{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {\n",
    "    \"CC\":\t\"coordinating conjunction\",\n",
    "    \"CD\":\t\"cardinal digit\",\n",
    "    \"DT\":\t\"determiner\",\n",
    "    \"EX\":\t\"existential there\",\n",
    "    \"FW\":\t\"foreign word\",\n",
    "    \"IN\":\t\"preposition/subordinating conjunction\",\n",
    "    \"JJ\":\t\"This NLTK POS Tag is an adjective (large)\",\n",
    "    \"JJR\":\t\"adjective, comparative (larger)\",\n",
    "    \"JJS\":\t\"adjective, superlative (largest)\",\n",
    "    \"LS\":\t\"list market\",\n",
    "    \"MD\":\t\"modal (could, will)\",\n",
    "    \"NN\":\t\"noun, singular (cat, tree)\",\n",
    "    \"NNS\":\t\"noun plural (desks)\",\n",
    "    \"NNP\":\t\"proper noun, singular (sarah)\",\n",
    "    \"NNPS\":\t\"proper noun, plural (indians or americans)\",\n",
    "    \"PDT\":\t\"predeterminer (all, both, half)\",\n",
    "    \"POS\":\t\"possessive ending (parent's)\",\n",
    "    \"PRP\":\t\"personal pronoun (hers, herself, him, himself)\",\n",
    "    \"PRP\":\t\"possessive pronoun (her, his, mine, my, our )\",\n",
    "    \"RB\":\t\"adverb (occasionally, swiftly)\",\n",
    "    \"RBR\":\t\"adverb, comparative (greater)\",\n",
    "    \"RBS\":\t\"adverb, superlative (biggest)\",\n",
    "    \"RP\":\t\"particle (about)\",\n",
    "    \"TO\":\t\"infinite marker (to)\",\n",
    "    \"UH\":\t\"interjection (goodbye)\",\n",
    "    \"VB\":\t\"verb (ask)\",\n",
    "    \"VBG\":\t\"verb gerund (judging)\",\n",
    "    \"VBD\":\t\"verb past tense (pleaded)\",\n",
    "    \"VBN\":\t\"verb past participle (reunified)\",\n",
    "    \"VBP\":\t\"verb, present tense not 3rd person singular(wrap)\",\n",
    "    \"VBZ\":\t\"verb, present tense with 3rd person singular (bases)\",\n",
    "    \"WDT\":\t\"wh-determiner (that, what)\",\n",
    "    \"WP\":\t\"wh- pronoun (who)\",\n",
    "    \"WRB\":\t\"wh- adverb (how)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/breno/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/breno/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nOutra maneira de generalizar a partir de um conjunto de exemplos seria construir um modelo desses exemplos e utilizar esse modelo para fazer previsões.', 'Isso é chamado de aprendizado baseado em modelo (Figura 1-16).']\n",
      "[['Outra', 'maneira', 'de', 'generalizar', 'a', 'partir', 'de', 'um', 'conjunto', 'de', 'exemplos', 'seria', 'construir', 'um', 'modelo', 'desses', 'exemplos', 'e', 'utilizar', 'esse', 'modelo', 'para', 'fazer', 'previsões', '.'], ['Isso', 'é', 'chamado', 'de', 'aprendizado', 'baseado', 'em', 'modelo', '(', 'Figura', '1-16', ')', '.']]\n",
      "[[('Outra', 'NNP'), ('maneira', 'NN'), ('de', 'FW'), ('generalizar', 'FW'), ('a', 'DT'), ('partir', 'NN'), ('de', 'IN'), ('um', 'JJ'), ('conjunto', 'NN'), ('de', 'IN'), ('exemplos', 'FW'), ('seria', 'NNS'), ('construir', 'VBP'), ('um', 'JJ'), ('modelo', 'NN'), ('desses', 'VBZ'), ('exemplos', 'JJ'), ('e', 'NN'), ('utilizar', 'JJ'), ('esse', 'NN'), ('modelo', 'NN'), ('para', 'NN'), ('fazer', 'NN'), ('previsões', 'NN'), ('.', '.')], [('Isso', 'NNP'), ('é', 'NNP'), ('chamado', 'NN'), ('de', 'FW'), ('aprendizado', 'FW'), ('baseado', 'FW'), ('em', 'FW'), ('modelo', 'FW'), ('(', '('), ('Figura', 'NNP'), ('1-16', 'CD'), (')', ')'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "import nltk    \n",
    "from nltk import tokenize    \n",
    "\n",
    "text = \"\"\"\n",
    "Outra maneira de generalizar a partir de um conjunto de exemplos seria construir um modelo desses exemplos e utilizar esse modelo para fazer previsões. Isso é chamado de aprendizado baseado em modelo (Figura 1-16).\"\"\"\n",
    "\n",
    "def preprocess_text(text):\n",
    "     sentence = nltk.sent_tokenize(text)\n",
    "     print(sentence)\n",
    "     sentence = [nltk.word_tokenize(s) for s in sentence]\n",
    "     print(sentence)\n",
    "     sentence = [nltk.pos_tag(s) for s in sentence]\n",
    "     print(sentence)\n",
    "\n",
    "tokenized = preprocess_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('last', 'JJ'),\n",
       " ('night', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('saw', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('black', 'JJ'),\n",
       " ('dog', 'NN'),\n",
       " ('barking', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('kid', 'NN')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram = (\"NP: {<DT>?<JJ>*<NN>}\")\n",
    "\n",
    "sent = \"last night i saw a black dog barking at a kid\"\n",
    "\n",
    "\n",
    "chunking = nltk.RegexpParser(gram)\n",
    "sent_token = nltk.word_tokenize(sent)\n",
    "tagging = nltk.pos_tag(sent_token)\n",
    "tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'svgling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/formatters.py:344\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    342\u001b[0m     method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n\u001b[1;32m    343\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m         \u001b[39mreturn\u001b[39;00m method()\n\u001b[1;32m    345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nltk/tree/tree.py:782\u001b[0m, in \u001b[0;36mTree._repr_svg_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_repr_svg_\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 782\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39msvgling\u001b[39;00m \u001b[39mimport\u001b[39;00m draw_tree\n\u001b[1;32m    784\u001b[0m     \u001b[39mreturn\u001b[39;00m draw_tree(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m_repr_svg_()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'svgling'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [Tree('NP', [('last', 'JJ'), ('night', 'NN')]), Tree('NP', [('i', 'NN')]), ('saw', 'VBD'), Tree('NP', [('a', 'DT'), ('black', 'JJ'), ('dog', 'NN')]), Tree('NP', [('barking', 'NN')]), ('at', 'IN'), Tree('NP', [('a', 'DT'), ('kid', 'NN')])])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = chunking.parse(tagging)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Outra', 'NNP'),\n",
       " ('maneira', 'NN'),\n",
       " ('de', 'FW'),\n",
       " ('generalizar', 'FW'),\n",
       " ('a', 'DT'),\n",
       " ('partir', 'NN'),\n",
       " ('de', 'IN'),\n",
       " ('um', 'JJ'),\n",
       " ('conjunto', 'NN'),\n",
       " ('de', 'IN'),\n",
       " ('exemplos', 'FW'),\n",
       " ('seria', 'NNS'),\n",
       " ('construir', 'VBP'),\n",
       " ('um', 'JJ'),\n",
       " ('modelo', 'NN'),\n",
       " ('desses', 'VBZ'),\n",
       " ('exemplos', 'JJ'),\n",
       " ('e', 'NN'),\n",
       " ('utilizar', 'JJ'),\n",
       " ('esse', 'NN'),\n",
       " ('modelo', 'NN'),\n",
       " ('para', 'NN'),\n",
       " ('fazer', 'NN'),\n",
       " ('previsões', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Isso', 'NNP'),\n",
       " ('é', 'NNP'),\n",
       " ('chamado', 'NN'),\n",
       " ('de', 'FW'),\n",
       " ('aprendizado', 'FW'),\n",
       " ('baseado', 'FW'),\n",
       " ('em', 'FW'),\n",
       " ('modelo', 'FW'),\n",
       " ('(', '('),\n",
       " ('Figura', 'NNP'),\n",
       " ('1-16', 'CD'),\n",
       " (')', ')'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_words = nltk.pos_tag(words)\n",
    "\n",
    "word_tags = []\n",
    "\n",
    "for tw in tagged_words:\n",
    "    word_tags.append(tw[0] + \"_\" + tw[1])\n",
    "                     \n",
    "tagged_paragraph = ' '.join(word_tags)\n",
    "\n",
    "# print(words[:5])\n",
    "# print(tagged_words[:5])\n",
    "\n",
    "tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Cerca de 35 milhões de argentinos estão convocados às urnas, em um país polarizado e assolado por uma das piores crises econômicas de sua história. De um lado está o ultraliberal Milei (A Liberdade Avança), que atrai o voto de protesto. De outro Massa (União pela Pátria), o peronista de centro-esquerda, que tenta pela segunda vez a escalada à Casa Rosada\n",
    "Os indecisos são vistos como fiel da balança da eleição. No primeiro turno, em 22 de outubro, Massa, atual ministro da Economia, surpreendeu, e obteve 36,7% dos votos, contra 29,9% de Milei — mas 33,24% dos eleitores não votaram em nenhum dos dois candidatos.\n",
    "\n",
    "Terceira colocada e eliminada da disputa, a conservadora Patricia Bullrich (Juntos pela Mudança), recebeu 23,8% dos votos e, para o segundo turno, decidiu apoiar Milei. Diante de uma participação de 77% do eleitorado, registrou-se 21% de votos em branco, de acordo com levantamento do Focus Group da Universidade de Buenos Aires.\n",
    "\n",
    "Massa nos últimos dias tentou convencer os indecisos com mensagens de apaziguamento. Prometeu superar as divisões políticas com um \"governo de unidade\" e apelou para o \"voto útil\" para salvaguardar o país — que completará 40 anos de democracia ininterrupta no dia em que o novo governo tomar posse, em 10 de dezembro.\n",
    "\n",
    "Já Milei, à frente de uma formação que inclui negacionistas da ditadura, apostou na tensão. Ele encerrou sua campanha com megacomício para 50 mil pessoas, lançando acusações de \"fraudes eleitorais\" — a exemplo do ex-presidente Jair Bolsonaro (PL) no Brasil\n",
    "\n",
    "As pesquisas de intenção de voto indicam um disputa acirrada. A maioria mostra Milei alguns pontos percentuais à frente ou dois tecnicamente empatados.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 => 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['convocados às urnas', 'união pela pátria']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
